# AUTOGENERATED! DO NOT EDIT! File to edit: 01_data_prepocess.ipynb (unless otherwise specified).

__all__ = ['say_hello', 'nlp_en', 'clean_punc', 'remove_stopword', 'nlp', 'cal_lemma', 'set_key', 'cal_lemma_pos']

# Cell
def say_hello(to):
    "Say hello to somebody"
    return f'Hello {to}!'

# Cell
import warnings
warnings.filterwarnings('ignore')
import numpy as np
import pandas as pd
import os
pd.set_option('display.max_columns', 500)
pd.set_option('display.max_colwidth', -1)
from nltk import sent_tokenize
import nltk
# import gensim
import string
from spacy.lang.en import English
from spacy.lang.en.stop_words import STOP_WORDS
from tqdm import tqdm
import spacy
import re
nlp_en = spacy.load("en_core_web_sm")

# Cell
def clean_punc(string,translator):
    string = string.translate(translator)

    return string

## remove stopwords
nlp = spacy.load("en_core_web_sm")
# nlp.Defaults.stop_words.add("teacher","student"])
# nlp.Defaults.stop_words |= {"teacher","student","students","lesson","class","pupil","pupils"}

def remove_stopword(string,nlp):
    doc = nlp(string)

    token_list = []
    for token in doc:
        token_list.append(token.text)

    filtered_sentence =[]
    for word in token_list:
        lexeme = nlp.vocab[word]
        if lexeme.is_stop == False:
            filtered_sentence.append(word)

    return ' '.join(i for i in filtered_sentence)

# Cell
def cal_lemma(string):
    doc = nlp(string)
    y = [x.lemma_ for x in doc]
    return ' '.join(i for i in y)

# Cell
# calculate POS and Lemma

def set_key(dictionary, key, value):
    if key not in dictionary:
        dictionary[key] = value
    elif type(dictionary[key]) == list:
        if value not in dictionary[key]:
            dictionary[key].append(value)
    else:
        dictionary[key] = [dictionary[key], value]

def cal_lemma_pos(x):
    s={}
    try:
        doc = nlp(x)
        y=[(x.pos_,x.lemma_) for x in doc]

        for i,j in y:
            set_key(s,i,j)
    except:
        pass
    return s